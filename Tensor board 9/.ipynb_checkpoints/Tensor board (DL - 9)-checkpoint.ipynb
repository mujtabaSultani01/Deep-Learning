{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37eb4a37",
   "metadata": {},
   "source": [
    "## Tensor board\n",
    "**TensorBoard** is a tool used for visualization in deep learning. It allows users to visualize data such as model graphs, scalar values, histograms, images, audio, and text. TensorBoard can help to identify patterns, debug models, and compare different runs of the same model. It provides useful visualizations that can facilitate better understanding of neural networks and help to improve their performance.\n",
    "* TensorBoard is a tool that allow you to debug the issues with neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f26d6",
   "metadata": {},
   "source": [
    "**So here we use the repeated source code which is a basic neural netwok for classification of hand written digits. Using that source code we want to look at some of the internal of the implemented neural network** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8b620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries...\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af433ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first load the hand written digits from keras datasets:\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886f9611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the lenght of x_train:\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec3fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check the lenght of x_test\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f3bd134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape of single image is:\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d123d152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef190a4100>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To display a specific image, so we use matshow function from matplolib library:\n",
    "plt.matshow(x_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f24b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is scalling the data which has more effect on model accuracy. So to scall the values, as we know that each\n",
    "# individual value is in range [0 to 255], so if we divide this whole array into 255, then it will be scalled from 0 to 1.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c77d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we need to flatten the 2D array into single dimension array, for that we do as follow:\n",
    "x_train_flattened = x_train.reshape(len(x_train), 28*28)\n",
    "x_test_flattened = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7552f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we check the shape of dataset, we see that it's single dimension array:\n",
    "x_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3fc1ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2719 - accuracy: 0.9228\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1190 - accuracy: 0.9653\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0833 - accuracy: 0.9746\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0637 - accuracy: 0.9808\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0500 - accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef17b0c730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next thing is, if you don't want to flatten your array, keras come with a function called 'flatten' which do the same for you.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f848d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2755 - accuracy: 0.9219\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1260 - accuracy: 0.9635\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0880 - accuracy: 0.9736\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0693 - accuracy: 0.9786\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0532 - accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef3ef44400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we see the result of my model training (loss, accuracy) but it's not much clear, if we want to see the model\n",
    "# accuracy that how it's going up and model loss how it's become low per each epoch, so tensor board provide that nice graph\n",
    "# for us. Tensor board provide some different functionality, this is one of them.\n",
    "# So we define the tensor board callbacks, which create log directory for saving all the logs. and then we supply it to the\n",
    "# fit function. Now when the tensorflow is running the training, it will use this call back and it will supply all the \n",
    "# information (loss, accuracy ...) per epoch to 'tb_callback' and 'tb_callback' will log all those events in the log \n",
    "# directory.\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/\", histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2969ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now the 'logs' directory is created. To see better visualization of thei train process we go to the same directory \n",
    "# through CMD or GitBash and run the 'tensorboard --logdir logs/' command. It will give you a URL, copy it and past it in \n",
    "# browser, so it will luch the tensorboard. So then we can see how the accuracy is increasing in each epoch. When you close\n",
    "# the mouse to the graph, it will tell everything in each epoch. You can also check the Graphs menu to see the graphs which\n",
    "# will tell you about all layers, used functions, and input sizes. Histogram will basically show you the weights (kernals) \n",
    "# and bias as well as number of epochs.\n",
    "# So this type of visualization will help us to debug the neural networks.\n",
    "\n",
    "# The other way of lunching tensorbord inside Jupyter notebook is to implement the following commad:\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir logs/fit\n",
    "\n",
    "# Both the ways are working but in separate URL through CMD will be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ccdd523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6692 - accuracy: 0.8302\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3426 - accuracy: 0.9043\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2946 - accuracy: 0.9165\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2647 - accuracy: 0.9250\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2418 - accuracy: 0.9316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef404011c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to change the 'optimizer = 'Adam'' parameter and store the result in the log directory but in separate dir:\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/SGD\", histogram_freq=1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556d598",
   "metadata": {},
   "source": [
    "* **So now we can choose one of them or both of them to compare the performance. We can uncheck the train option and compare the performance of the two optimizer.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
