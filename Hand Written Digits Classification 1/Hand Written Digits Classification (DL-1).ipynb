{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2875e6a3",
   "metadata": {},
   "source": [
    "## Hand Written Digits Classification \n",
    "here we're classifying handwritten digits using deep neural network. The digits are first input into the network and the network is then trained to recognize the digits. The network is then able to classify the digits into one of the predefined classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e6974",
   "metadata": {},
   "source": [
    "<img src = \"digits_nn.jpg\" width = \"700px\" height = \"450px\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2dee9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ab9891d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# So first we load the data from keras dataset:\n",
    "# Note: The mnist.npz file is manually downloaded and stored in .keras/datasets directory.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fe9cdbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the lenght of x_train:\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68e88754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the lenght of x_test:\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da3a288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The see each individual sample:\n",
    "x_train[0].shape   # Each sample is 28*28 fixel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4d740c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the way each sample is represented is simple 2D array:\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cfcee7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d3d2f9e730>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If we want to plot an individual image, so we can use 'matplotlib' library:\n",
    "plt.matshow(x_train[2])    # The 3rd image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "409167d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So if we check which number is in reality on index 2:\n",
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c2ac59e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To print first 10 samples of y_train, so:\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ff8c6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The current shape of the x_train set is:\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "92f00ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next step is to platten the dataset. It means now we have 2D array but we want to convert it to 1D array(60000, 784). \n",
    "# So 1D  could be fed into the input layer of our deep learning model. To platten the 2D array, in pandas there is a \n",
    "# function called reshape which can do the conversion. The first argument is the lenght of array which is 'len(x_train)' \n",
    "# and the 2nd argument takes 28*28 to create a single dimension array.\n",
    "usc_x_train_plattened = x_train.reshape(len(x_train), 28*28)\n",
    "usc_x_train_plattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bed7b734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To print the shape of plattened array:\n",
    "usc_x_train_plattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8c9ac664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly to reshape the x_test:\n",
    "usc_x_test_plattened = x_test.reshape(len(x_test), 28*28)\n",
    "usc_x_test_plattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f28a3ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to see the first individual element which should be 1-D:\n",
    "usc_x_train_plattened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aafcd6a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 9.4760 - accuracy: 0.8417\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 6.1177 - accuracy: 0.8792\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.7398 - accuracy: 0.8826\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.5553 - accuracy: 0.8849\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2416 - accuracy: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d38ad01d30>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create a simple neural network which has just two layers (input and output). The way we create it, we call sequential() from keras. Sequential means that we have a stack of lequential layers in my neural network.\n",
    "# So sequential accept every layer as one element, so the first element here is input which is dense (every neuron is connected with each of the neuron of the next layer). Then we define the input shape (784) and the output shape is 10.\n",
    "# So in this way we're defining both input and output layers. The next argument is activation function which is 'sigmoid'.\n",
    "# In the next step we compile our model and we pass a bunch of parameters. The parameters will be coverd in the feature videos.\n",
    "# Next we trained the model.\n",
    "\n",
    "Unscalled_model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "Unscalled_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "Unscalled_model.fit(usc_x_train_plattened, y_train, epochs=5)\n",
    "# After running it's going on each sample in each epochs... and at the end of each epoch it's measuring the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "037ec869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 5.1246 - accuracy: 0.8956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.124635219573975, 0.8956000208854675]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we see that the time goes the accuracy is getting better and the loss is become smaller.\n",
    "# To test the model on test dataset:\n",
    "Unscalled_model.evaluate(usc_x_test_plattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "70abda28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d38af8b8b0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To see the image on index 6:\n",
    "plt.matshow(x_test[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "55ce4529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.000000e+00, 0.000000e+00, 0.000000e+00, 2.063326e-06,\n",
       "       1.000000e+00, 1.000000e+00, 9.201727e-37, 9.999983e-01,\n",
       "       1.000000e+00, 1.000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we see the result on un scalled model:\n",
    "usc_y_predicted = Unscalled_model.predict(usc_x_test_plattened)\n",
    "usc_y_predicted[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "da9836d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to see the simple prediction on the model using numpy 'argmax' function, which find the max value and return the relevant index.\n",
    "np.argmax(usc_y_predicted[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865cbcb",
   "metadata": {},
   "source": [
    "* We see the model is performing better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1458661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the accuracy is not bad in the previous model but if we scall the values then we'll get better accuracy than the previous one. So to scall the values, as we know that each\n",
    "# individual value is in range [0 to 255], so if we divide this whole array into 255, then it will be scalled from 0 to 1.\n",
    "x_train = x_train/255\n",
    "y_test = y_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e249428f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now when we see the x_train or y_test, the values will be in [0 to 1] range:\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "70bbb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we again reshape the x_train and x_test:\n",
    "sc_x_train_plattened = x_train.reshape(len(x_train), 28*28)\n",
    "sc_x_test_plattened = x_test.reshape(len(x_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0b649a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4711 - accuracy: 0.8775\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3045 - accuracy: 0.9156\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2836 - accuracy: 0.9199\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2737 - accuracy: 0.9236\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2666 - accuracy: 0.9255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3ea97a700>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So again we create and train the model:\n",
    "scalled_model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "scalled_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=\"accuracy\"\n",
    ")\n",
    "\n",
    "scalled_model.fit(sc_x_train_plattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4c8f953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2625.6060 - accuracy: 0.0966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2625.60595703125, 0.0966000035405159]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we see the accuracy which is better than previous time. \n",
    "# Now let's evaluate the accuray on test dataset, because the previous accuracy was on train dataset:\n",
    "scalled_model.evaluate(sc_x_test_plattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "341a2e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d385afb070>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The scalled model accuracy is looking very bad on test dataset, the reason is splitting the dataset into train and test samples.\n",
    "# Now let's have a simple prediction:\n",
    "plt.matshow(x_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "342a5401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if we see the result on scalled model:\n",
    "sc_y_predicted = scalled_model.predict(x_test_plattened)\n",
    "sc_y_predicted[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6915ef1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy 'argmax' function will find the maximum value and will output the related index.\n",
    "np.argmax(sc_y_predicted[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b76a04",
   "metadata": {},
   "source": [
    "* So we know that the model on test samples had very bad accuracy, as result the prediction is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1459a9",
   "metadata": {},
   "source": [
    "* <p style = \"color:green\">This notebook was just for practice, follow the complete process of hand written digits classification using neural network in 'Hand Written Digits Classification 2 (DL-1) notebook.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
